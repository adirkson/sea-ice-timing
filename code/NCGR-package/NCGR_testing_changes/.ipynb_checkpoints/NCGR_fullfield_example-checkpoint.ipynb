{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing NCGR on a full field\n",
    "\n",
    "* This notebook walks you through how to perform non-homoegenous Gaussian regression (NCGR) on an ice-free date or freeze-up date forecast at every grid cell.\n",
    "\n",
    "* This option is **useful if you *do want* to rely on NetCDF dependencies**. This is the most straightforward way to perform the NCGR calibration in one go for the whole domain provided. Using this approach, an output NetCDF file is create that can be used to easily plot the probabilistic forecasts for early, near-normal, and late ice retreat or advance.\n",
    "\n",
    "* You should have already installed the `NCGR` package before running this notebook.\n",
    "\n",
    "* The first section of this notebook, **Bare-bones code**, just offers a copy and pasteable section of code that performs NCGR with `ncgr.ncgr_fullfield()`.\n",
    "\n",
    "* The second section of the notebook, **Detailed explanation and plotting** goes through step-by-step and provides insights on each piece of code, as well as on the input NetCDF files required, and creates plots showing the results. This section requires that cartopy be installed (see https://github.com/SciTools/cartopy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bare-bones code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import ncgr\n",
    "import sitdates as sitdates\n",
    "\n",
    "event = 'ifd'\n",
    "im = 6 # initialization month\n",
    "\n",
    "# instantiate the sitdates class\n",
    "si_time = sitdates.sitdates(event=event)\n",
    "a = si_time.pre_occurence(im) # minimum date possible\n",
    "b = si_time.non_occurence(im) # maximum date possible\n",
    "\n",
    "# input filenames\n",
    "hc_netcdf = './Data/ifd_hc_1979_2017_im06.nc' # training hindcasts\n",
    "obs_netcdf = './Data/ifd_obs_1979_2017_im06.nc' # training observations\n",
    "fcst_netcdf = './Data/ifd_fcst_2018_im06.nc' # forecast\n",
    "clim_netcdf = './Data/ifd_clim_2008_2017_im06.nc' # observations for reference climatology\n",
    "\n",
    "# output filename (this usually doesn't exist yet)\n",
    "out_netcdf = './Data/ifd_fcst_2018_im06_ncgr.nc'\n",
    "\n",
    "\n",
    "# calibrate \n",
    "ncgr.ncgr_fullfield(hc_netcdf, obs_netcdf, fcst_netcdf, out_netcdf, event,\n",
    "                  a, b, clim_netcdf=clim_netcdf) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed explanation and plotting\n",
    "\n",
    "Import necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ncgr\n",
    "import sitdates\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "import netCDF4 as nc4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now define the variables that will be used as arguments in `ncgr.ncgr_fullfield()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=151, b=273\n"
     ]
    }
   ],
   "source": [
    "event='ifd' \n",
    "\n",
    "im = 6 # initialization month\n",
    "\n",
    "# instantiate the sitdates class\n",
    "si_time = sitdates.sitdates(event=event)\n",
    "a = si_time.pre_occurence(im) # minimum date possible\n",
    "b = si_time.non_occurence(im) # maximum date possible\n",
    "print(\"a=%d, b=%d\"%(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above section of code, we've made use of the `sidates` module by instantiating it with the event variable (in this case 'ifd' for *ice-free date*). By doing so, and by calling on `si_time.pre_occurence()` and `si_time.non_occurence()` with the initialization month as an input argument, the minimum and maximum dates possible are returned. These are printed as `a=151` and `b=273`. Reading the documentation for `sidates.sitdates()` you'll see that default dates are set to those given in [1]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Useful side-note:*\n",
    "If rather different conventions are used for your data, you can change the dates associated with `si_time.pre_occurence()` and `si_time.non_occurence()` using `si_time.set_min_date()` and `si_time.set_min_date()`. For example, for `im=7`, the convention is to consider the ice-free date for the melt season of the following yea. If rather your hindcast and observed data are such that the ice-free date is for the current season, you could change the minimum and maximum dates corresponding to `im=7` accordingly with e.g.:\n",
    "\n",
    "```python\n",
    "si_time.set_min_date(im, 181) # day before initialization (June 31) of the current year\n",
    "si_time.set_max_date(im, 273) # September 31 of the current year (last day of the melt season)\n",
    "```\n",
    "Those dates are then set and the minimum and maximum dates can be retrieved at any time within the working script using:\n",
    "\n",
    "```python\n",
    "a = si_time.pre_occurence(im)\n",
    "b = si_time.non_occurence(im)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create variables pointing to the different NetCDF files that are to be read in when calling on `ncgr.ncgr_fullfield`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input filenames\n",
    "hc_netcdf = './Data/ifd_hc_1979_2017_im06.nc' # training hindcasts\n",
    "obs_netcdf = './Data/ifd_obs_1979_2017_im06.nc' # training observations\n",
    "fcst_netcdf = './Data/ifd_fcst_2018_im06.nc' # forecast\n",
    "clim_netcdf = './Data/ifd_clim_2008_2017_im06.nc' # observations for reference climatology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Details of input NetCDF files\n",
    "\n",
    "* All of the files provided as input arguments to `ncgr.ncgr_fullfield()` should be CF compliant (<http://cfconventions.org/>). The files included in this demo referenced above can be downloaded at https://adirkson.github.io/sea-ice-timing/.\n",
    "\n",
    "* As currently written, all of the files must have the same spatial coordinates. \n",
    "\n",
    "* The `hc_netcdf` and `obs_netcdf` files must contain data for the same years, and *should not* contain data corresponding to the year of the forecast to be calibrated.\n",
    "\n",
    "* Related to the previous point, the year of the forecast to be calibrated (i.e. for the `fcst_netcdf` file) needn't proceed the period covered in the `hc_netcdf` and `obs_netcdf` files. For instance, if the forecast to be calibrated were for 2002, the `hc_netcdf` and `obs_netcdf` files could contain data for any year except 2002.\n",
    "\n",
    "* While technically speaking the year of the forecast to be calibrated and the years used for training don't need to be consecutive, it isn't recommended to have large gaps in the training record prior to the year of the forecast. For instance, if a forecast for the melt season of 2020 were being calibrated, it is recommended that the training data are available through 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hc_netcdf\n",
    "\n",
    "* Must contain a variable with the name {'ifd','fud'}. These are the ensemble hindcast ice-free dates (if 'ifd') or freeze-up dates (if 'fud') in day-of-year format (e.g. 1=Jan. 1, 273=Sep. 31, 365=Dec. 31).\n",
    "* Dimensions of {'ifd','fud'} must be: `('time','ensemble','lat',lon')` *or* `('time','ensemble','latitude',longitude')` *or* `('time','ensemble','Y',X')`.\n",
    "* The time variable in this file is associated with the start dates of the hindcasts (e.g. 01/06/1979, 01/06/1980, ..., 01/06/2017 but in NetCDF time format). This is needed in order for several time-type variables to be create in `ncgr.ncgr_fullfield()`.\n",
    "* Masked values are ignored in calibration and the output file created will contain masked values in the same locations.\n",
    "* The next two cells print the dimensions and variables in this file and print the time variable in datetime object format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 39\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'longitude', size = 128\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'latitude', size = 18\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'ensemble', size = 10\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 time(time)\n",
      "    units: days since 1900-01-01\n",
      "    long_name: time\n",
      "    calendar: standard\n",
      "unlimited dimensions: time\n",
      "current shape = (39,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 longitude(longitude)\n",
      "    units: degrees_east\n",
      "    long_name: longitude\n",
      "    standard_name: longitude\n",
      "    axis: X\n",
      "unlimited dimensions: \n",
      "current shape = (128,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 latitude(latitude)\n",
      "    units: degrees_north\n",
      "    long_name: latitude\n",
      "    standard_name: latitude\n",
      "    axis: Y\n",
      "unlimited dimensions: \n",
      "current shape = (18,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 ifd(time, ensemble, latitude, longitude)\n",
      "    long_name: ice-free date\n",
      "unlimited dimensions: time\n",
      "current shape = (39, 10, 18, 128)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n"
     ]
    }
   ],
   "source": [
    "dsin = Dataset(hc_netcdf)\n",
    "for d in dsin.dimensions:\n",
    "    print(dsin.dimensions[d])\n",
    "\n",
    "for v in dsin.variables:\n",
    "    print(dsin.variables[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cftime.DatetimeGregorian(1979-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(1980-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(1981-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(1982-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(1983-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(1984-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(1985-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(1986-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(1987-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(1988-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(1989-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(1990-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(1991-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(1992-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(1993-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(1994-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(1995-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(1996-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(1997-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(1998-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(1999-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(2000-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(2001-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(2002-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(2003-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(2004-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(2005-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(2006-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(2007-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(2008-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(2009-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(2010-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(2011-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(2012-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(2013-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(2014-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(2015-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(2016-06-01 00:00:00)\n",
      " cftime.DatetimeGregorian(2017-06-01 00:00:00)]\n"
     ]
    }
   ],
   "source": [
    "# retrieve the 'time' variable and print it as a datetime object\n",
    "time_var = Dataset(hc_netcdf).variables['time']\n",
    "print(nc4.num2date(time_var[:], units=time_var.units, calendar=time_var.calendar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `obs_netcdf`\n",
    "* Same requirements as `hc_netcdf`, except that the dimensions of `{'ifd','fud'}` should exlude the `ensemble` dimension.\n",
    "* The `{'ifd','fud'}` variable should follow the same conventions as used for the `{'ifd','fud'}` variable in `hc_netcdf`.\n",
    "* As stated above, the 'time' variable should match that in `hc_netcdf`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fcst_netcdf`\n",
    "* Same requirements as `hc_netcdf`, except that the 'time' variable should be a single value equal to the forecast start date. For this example we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cftime.DatetimeGregorian(2018-06-01 00:00:00)]\n"
     ]
    }
   ],
   "source": [
    "# retrieve the 'time' variable and print it as a datetime object\n",
    "time_var = Dataset(fcst_netcdf).variables['time']\n",
    "print(nc4.num2date(time_var[:], units=time_var.units, calendar=time_var.calendar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `clim_netcdf`\n",
    "* Same requirements as `obs_netcdf`.\n",
    "* Usually this is just a subset of dates from `obs_netcdf`. In fact, the file associated with the `clim_netcdf` variable was created using the following line of CDO code: `cdo selyears,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017 obs_netcdf clim_netcdf`\n",
    "    \n",
    "## Calibration\n",
    "\n",
    "Now create a variable pointing to the path/filename of the NetCDF file that will be written during the call to `ncgr.ncg_fullfield`, and make the function call to calibrate. This takes about 8 or 9 minutes on my personal laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output filename (this usually doesn't exist yet)\n",
    "out_netcdf = './Data/ifd_fcst_2018_im06_ncgr.nc'\n",
    "\n",
    "ncgr.ncgr_fullfield(hc_netcdf, obs_netcdf, fcst_netcdf, out_netcdf, event,\n",
    "                  a, b, clim_netcdf=clim_netcdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "An output file `./Data/ifd_fcst_2018_im06_ncgr_pre-made.nc` already exists that we'll now use to plot the probabilistic forecast as a three category forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "clim_yr_s = 2008\n",
    "clim_yr_f = 2017\n",
    "\n",
    "fcst_yr = 2018\n",
    "im_id = '%02d'%im\n",
    "###########################\n",
    "ncgr_fcst_file = Dataset(\"./Data/ifd_fcst_2018_im06_ncgr_pre-made.nc\")\n",
    "ncgr_p_en = ncgr_fcst_file['prob_EN'][:][0]\n",
    "ncgr_p_nn = ncgr_fcst_file['prob_NN'][:][0]\n",
    "ncgr_p_ln = ncgr_fcst_file['prob_LN'][:][0]\n",
    "\n",
    "fill_value = ncgr_fcst_file['prob_EN']._FillValue\n",
    "\n",
    "ncgr_p_en[ncgr_p_en==fill_value] = np.nan\n",
    "ncgr_p_nn[ncgr_p_nn==fill_value] = np.nan\n",
    "ncgr_p_ln[ncgr_p_ln==fill_value] = np.nan\n",
    "\n",
    "\n",
    "lat = ncgr_fcst_file['latitude'][:]\n",
    "lon = ncgr_fcst_file['longitude'][:]\n",
    "\n",
    "LON, LAT = np.meshgrid(lon,lat)\n",
    "\n",
    "\n",
    "# prep arrays to be filled with most likely category probability\n",
    "ncgr_p_en_new = np.zeros(ncgr_p_en.shape)\n",
    "ncgr_p_nn_new = np.zeros(ncgr_p_nn.shape)\n",
    "ncgr_p_ln_new = np.zeros(ncgr_p_ln.shape)\n",
    "\n",
    "# if category is most likely, set to the probability for that category (else it will be zero)\n",
    "ncgr_p_en_new[ncgr_p_en==np.nanmax(np.array([ncgr_p_en,ncgr_p_nn,ncgr_p_ln]),axis=0)] = ncgr_p_en[ncgr_p_en==np.nanmax(np.array([ncgr_p_en,ncgr_p_nn,ncgr_p_ln]),axis=0)]\n",
    "ncgr_p_nn_new[ncgr_p_nn==np.nanmax(np.array([ncgr_p_en,ncgr_p_nn,ncgr_p_ln]),axis=0)] = ncgr_p_nn[ncgr_p_nn==np.nanmax(np.array([ncgr_p_en,ncgr_p_nn,ncgr_p_ln]),axis=0)]\n",
    "ncgr_p_ln_new[ncgr_p_ln==np.nanmax(np.array([ncgr_p_en,ncgr_p_nn,ncgr_p_ln]),axis=0)] = ncgr_p_ln[ncgr_p_ln==np.nanmax(np.array([ncgr_p_en,ncgr_p_nn,ncgr_p_ln]),axis=0)]\n",
    "\n",
    "\n",
    "########### Plotting  #####################\n",
    "def Add_Lon_Data(data,LAT,LON):\n",
    "    # adds a synthetic longitude to data at 360 in order to get\n",
    "    # rid of plotting discontinuity at 0/360\n",
    "    lat_new = LAT[:,0]\n",
    "    lon_new = np.append(LON[0,:],360.)\n",
    "    LON_new, LAT_new = np.meshgrid(lon_new,lat_new)\n",
    "    data_new = np.zeros(LON_new.shape)\n",
    "    data_new[:,:-1] = np.copy(data)\n",
    "    data_new[:,-1] = np.copy(data[:,-1])\n",
    "    return data_new\n",
    "\n",
    "def Add_Lon_Grid(LAT,LON):\n",
    "    # adds a synthetic longitude to the LAT and LON matrices\n",
    "    lat_new = LAT[:,0]\n",
    "    lon_new = np.append(LON[0,:],360.)\n",
    "    LON_new, LAT_new = np.meshgrid(lon_new,lat_new)\n",
    "    \n",
    "    return LAT_new, LON_new, LAT_new.shape[0], LAT_new.shape[1]\n",
    "\n",
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    # cuts off the ends of cmap colors at minval and maxval\n",
    "    new_cmap = mpl.colors.LinearSegmentedColormap.from_list(\n",
    "    'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "    cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap\n",
    "\n",
    "def set_up_subplot(fig,subplot=111):\n",
    "    crs_np = ccrs.NorthPolarStereo(central_longitude=-45)\n",
    "    ax = fig.add_subplot(subplot,projection=crs_np)\n",
    "    \n",
    "    xll, yll = crs_np.transform_point(279.26,33.92, ccrs.Geodetic())\n",
    "    xur, yur = crs_np.transform_point(102.34,31.37, ccrs.Geodetic())\n",
    "    \n",
    "    ax.set_extent([xll,xur,yll,yur],crs=crs_np)\n",
    "\n",
    "    ax.add_feature(cfeature.OCEAN,facecolor='c', zorder=1)\n",
    "    ax.add_feature(cfeature.LAND,facecolor='0.75', zorder=3)\n",
    "    ax.add_feature(cfeature.LAKES,facecolor='c',linestyle='-', edgecolor='k',zorder=3)\n",
    "    ax.coastlines(resolution='110m',linewidth=1,color='k',zorder=3)       \n",
    "    return ax\n",
    "\n",
    "clevs = [0.4, 0.6, 0.8, 1.0]\n",
    "clevs_lab = ['40','60','80','100']\n",
    "clevs_lab = [n+'%' for n in clevs_lab]\n",
    "clevs_ticks = np.array(clevs)\n",
    "\n",
    "# colormaps for each category\n",
    "cmap_en = cm.YlOrRd\n",
    "cmap_nn = cm.Greens\n",
    "cmap_ln = cm.Blues\n",
    "\n",
    "cmap_en = truncate_colormap(cmap_en,0.3,1.0)\n",
    "cmap_nn = truncate_colormap(cmap_nn,0.3,1.0)\n",
    "cmap_ln = truncate_colormap(cmap_ln,0.3,1.0)\n",
    "\n",
    "cmap_en.set_under('0.75')\n",
    "cmap_nn.set_under('0.75')\n",
    "cmap_ln.set_under('0.75')\n",
    "\n",
    "cmap_en.set_over(cm.YlOrRd(256))\n",
    "cmap_nn.set_over(cm.Greens(256))\n",
    "cmap_ln.set_over(cm.Blues(256))\n",
    "\n",
    "norm_en = mpl.colors.BoundaryNorm(clevs, cmap_en.N)\n",
    "norm_nn = mpl.colors.BoundaryNorm(clevs, cmap_nn.N)\n",
    "norm_ln = mpl.colors.BoundaryNorm(clevs, cmap_ln.N)\n",
    "\n",
    "LAT_new, LON_new, nlat_new, nlon_new = Add_Lon_Grid(LAT, LON)\n",
    "ncgr_p_en_new = Add_Lon_Data(ncgr_p_en_new, LAT, LON)\n",
    "ncgr_p_nn_new = Add_Lon_Data(ncgr_p_nn_new, LAT, LON)\n",
    "ncgr_p_ln_new = Add_Lon_Data(ncgr_p_ln_new, LAT, LON)\n",
    "\n",
    "\n",
    "fig = plt.figure(num=1,figsize=(8.5,9))\n",
    "plt.clf()\n",
    "\n",
    "#############################################################\n",
    "ax = set_up_subplot(fig)\n",
    "datain1 = np.copy(ncgr_p_en_new)\n",
    "masked_array1 = np.ma.array(datain1, mask=datain1==0.0)\n",
    "\n",
    "datain2 = np.copy(ncgr_p_nn_new)\n",
    "masked_array2 = np.ma.array(datain2, mask=datain2==0.0)\n",
    "\n",
    "datain3 = np.copy(ncgr_p_ln_new)\n",
    "masked_array3 = np.ma.array(datain3, mask=datain3==0.0)\n",
    "\n",
    "\n",
    "im1 = ax.pcolormesh(LON_new,LAT_new,masked_array1,vmin=0.4,vmax=1.0,\n",
    "              cmap=cmap_en,norm=norm_en,rasterized=True,transform=ccrs.PlateCarree(), zorder=2) \n",
    "\n",
    "im2 = ax.pcolormesh(LON_new,LAT_new,masked_array2,vmin=0.4,vmax=1.0,\n",
    "              cmap=cmap_nn,norm=norm_nn,rasterized=True,transform=ccrs.PlateCarree(), zorder=2)\n",
    "\n",
    "im3 = ax.pcolormesh(LON_new,LAT_new,masked_array3,vmin=0.4,vmax=1.0,\n",
    "              cmap=cmap_ln,norm=norm_ln,rasterized=True,transform=ccrs.PlateCarree(), zorder=2)\n",
    "\n",
    "ax.outline_patch.set_linewidth(1.5)\n",
    "\n",
    "cbar_ax1 = fig.add_axes([0.035, 0.04, 0.025, 0.25])\n",
    "cb1 = fig.colorbar(im1,cax=cbar_ax1,orientation='vertical',format='%d', ticks=clevs_ticks,\n",
    "             spacing='uniform', drawedges=True, extend='min', boundaries=[0]+clevs, extendfrac='auto')\n",
    "cbar_ax1.set_yticklabels(clevs_lab,fontsize=10)\n",
    "\n",
    "cbar_ax2 = fig.add_axes([0.035, 0.34, 0.025, 0.25])\n",
    "cb2 = fig.colorbar(im2,cax=cbar_ax2,orientation='vertical',format='%d', ticks=clevs_ticks,\n",
    "             spacing='uniform',drawedges=True, extend='min', boundaries=[0]+clevs, extendfrac='auto')\n",
    "cbar_ax2.set_yticklabels(clevs_lab,fontsize=10)\n",
    "\n",
    "cbar_ax3 = fig.add_axes([0.035, 0.63, 0.025, 0.25])\n",
    "cb3 = fig.colorbar(im3,cax=cbar_ax3,orientation='vertical',format='%d', ticks=clevs_ticks,\n",
    "             spacing='uniform',drawedges=True, extend='min', boundaries=[0]+clevs,  extendfrac='auto')\n",
    "\n",
    "cbar_ax1.set_yticklabels(clevs_lab,fontsize=14)\n",
    "cbar_ax2.set_yticklabels(clevs_lab,fontsize=14)\n",
    "cbar_ax3.set_yticklabels(clevs_lab,fontsize=14)\n",
    "\n",
    "cbar_ax1.set_ylabel('Early', fontsize=16,fontweight='semibold')\n",
    "cbar_ax2.set_ylabel('Near-normal', fontsize=16,fontweight='semibold')\n",
    "cbar_ax3.set_ylabel('Late', fontsize=16,fontweight='semibold')\n",
    "\n",
    "cbar_ax1.yaxis.set_label_position('left')\n",
    "cbar_ax2.yaxis.set_label_position('left')\n",
    "cbar_ax3.yaxis.set_label_position('left')\n",
    "\n",
    "\n",
    "cb1.outline.set_linewidth(2)\n",
    "cb1.outline.set_edgecolor('k')\n",
    "cb1.dividers.set_color('w')\n",
    "cb1.dividers.set_linewidth(1.5)\n",
    "\n",
    "cb2.outline.set_linewidth(2)\n",
    "cb2.outline.set_edgecolor('k')\n",
    "cb2.dividers.set_color('w')\n",
    "cb2.dividers.set_linewidth(1.5)\n",
    "\n",
    "cb3.outline.set_linewidth(2)\n",
    "cb3.outline.set_edgecolor('k')\n",
    "cb3.dividers.set_color('w')\n",
    "cb3.dividers.set_linewidth(1.5)\n",
    "\n",
    "fig.text(0.065,0.06,'EC',fontsize=14)\n",
    "fig.text(0.065,0.36,'EC',fontsize=14)\n",
    "fig.text(0.065,0.65,'EC',fontsize=14)\n",
    "\n",
    "fig.subplots_adjust(left=0.05, right=0.98, top=0.91, bottom=0.01)\n",
    "\n",
    "ax.set_title('Probability for Early, Near-normal, or Late '+event.upper()+' \\n From '+im_id+'/'+str(fcst_yr)+' (cf '+str(clim_yr_s)+'-'+str(clim_yr_f)+')',\n",
    "        fontsize=20,pad=10.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
